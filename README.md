# ğŸ¥ WatchAI

**WatchAI** is an AI-powered video recommendation platform that leverages deep learning and behavioral insights to deliver personalized video discovery. Using multi-modal AI analysis, it goes beyond traditional tags to understand video content through computer vision, audio processing, and natural language understanding.

ğŸ”— **[Live Demo](https://watchai-ten.vercel.app/)** | ğŸ“± **[Backend Pipeline](https://github.com/IG05/testing)**

---

## ğŸš€ Features

- ğŸ¬ **Smart Video Discovery**: AI-powered recommendations tailored to your interests
- ğŸ§  **Multi-Modal AI Analysis**:
  - ğŸ‘ï¸ Computer Vision via CLIP for visual understanding
  - ğŸ¤ Audio Processing via Whisper for speech-to-text
  - ğŸ“ NLP Embeddings for semantic content analysis
- ğŸ¯ **Dynamic User Profiling**: Adapts with every video you watch
- âš¡ **Real-Time Recommendations**: Instant similarity search using FAISS
- ğŸ“Š **Behavioral Insights**: Smart filtering based on viewing habits
- ğŸŒ **Responsive Design**: Seamless experience across all devices

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Next.js** with TypeScript
- **TailwindCSS** for styling
- **React** for interactive UI
- **Vercel** for deployment

### Backend & AI Pipeline
- **Python** ML pipeline with containerization
- **Docker** for containerized deployment
- **Google Cloud Run** for scalable ML processing
- **AWS S3** for video storage and management

### AI/ML Models
- **CLIP** - Computer vision and image understanding
- **Whisper** - Audio transcription and processing
- **NLP Embeddings** - Semantic text analysis
- **FAISS** - Fast similarity search and indexing

### Cloud & DevOps
- **Docker** containerization
- **Google Cloud Platform** for ML services
- **Amazon Web Services** for storage
- **Vercel** for frontend hosting
- **CI/CD** automated deployment pipeline

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI    â”‚    â”‚  Python ML       â”‚    â”‚   Cloud         â”‚
â”‚   (Vercel)      â”‚â—„â”€â”€â–ºâ”‚  Pipeline        â”‚â—„â”€â”€â–ºâ”‚   Storage       â”‚
â”‚                 â”‚    â”‚  (Cloud Run)     â”‚    â”‚   (AWS S3)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
         â”‚              â”‚  AI Models      â”‚             â”‚
         â”‚              â”‚  â€¢ CLIP         â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â€¢ Whisper      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚  â€¢ NLP/FAISS    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ and npm
- Python 3.8+
- Docker (optional, for containerization)
- Google Cloud SDK (for deployment)
- AWS CLI (for S3 setup)

### 1. Clone the Repository

```bash
git clone https://github.com/IG05/watchai.git
cd watchai
```

### 2. Frontend Setup

```bash
# Install dependencies
npm install

# Run development server
npm run dev
```

Access the app at `http://localhost:3000`

### 3. Backend Pipeline Setup

```bash
# Clone the ML pipeline repository
git clone https://github.com/IG05/testing.git
cd testing

# Install Python dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys and configurations
```

### 4. Docker Deployment (Optional)

```bash
# Build the container
docker build -t watchai-pipeline .

# Run locally
docker run -p 8000:8000 watchai-pipeline

# Deploy to Google Cloud Run
gcloud run deploy watchai-pipeline --source .
```

---

## âš™ï¸ Environment Variables

### Frontend (.env.local)
```env
NEXT_PUBLIC_API_URL=your_backend_api_url
NEXT_PUBLIC_AWS_REGION=your_aws_region
```

### Backend (.env)
```env
# AWS Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_S3_BUCKET=your_s3_bucket_name

# Google Cloud
GOOGLE_CLOUD_PROJECT=your_gcp_project_id

# API Keys
OPENAI_API_KEY=your_openai_key (if using OpenAI models)
```

---

## ğŸ§  How It Works

1. **ğŸ“¹ Video Input**: Users upload or browse videos on the platform
2. **ğŸ” Multi-Modal Analysis**: 
   - CLIP extracts visual features and context
   - Whisper processes audio for transcription
   - NLP models analyze semantic content
3. **ğŸ“Š Feature Extraction**: Deep embeddings generated for comprehensive understanding
4. **ğŸ‘¤ User Profiling**: Dynamic profiles built from viewing behavior and preferences
5. **ğŸ¯ Similarity Matching**: FAISS performs fast vector similarity search
6. **ğŸ“± Personalized Delivery**: Real-time recommendations served to users

---

## ğŸ“ˆ Performance & Scalability

- **âš¡ Fast Similarity Search**: FAISS enables sub-second recommendation generation
- **ğŸ³ Containerized Deployment**: Docker ensures consistent environments
- **â˜ï¸ Cloud-Native Architecture**: Auto-scaling with Google Cloud Run
- **ğŸ—„ï¸ Efficient Storage**: AWS S3 for reliable video storage and retrieval
- **ğŸ“Š Real-time Processing**: Streaming analysis for immediate insights

---

## ğŸ§ª API Endpoints

### Video Analysis
```bash
POST /api/analyze
Content-Type: application/json
{
  "video_url": "s3://bucket/video.mp4",
  "user_id": "user123"
}
```

### Get Recommendations
```bash
GET /api/recommendations?user_id=user123&limit=10
```

### User Profile
```bash
GET /api/profile?user_id=user123
POST /api/profile/update
```

---

## ğŸ› ï¸ Development

### Running Tests
```bash
# Frontend tests
npm test

# Backend tests
cd testing
python -m pytest
```

### Building for Production
```bash
# Frontend build
npm run build

# Docker production build
docker build -t watchai-prod --target production .
```

---

## ğŸ¯ Future Enhancements

- ğŸ¬ **Advanced Video Analytics**: Emotion detection and scene analysis
- ğŸ—£ï¸ **Real-time Transcription**: Live video processing capabilities  
- ğŸ“Š **Analytics Dashboard**: Detailed insights for content creators
- ğŸ¤– **Conversational AI**: Chat-based video discovery
- ğŸŒ **Multi-language Support**: Global content recommendations
- ğŸ“± **Mobile App**: Native iOS/Android applications

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Contact & Links

**Ishaan Goyal**
- ğŸ“§ Email: [ishaangoyal0610@gmail.com](mailto:ishaangoyal0610@gmail.com)
- ğŸ’¼ LinkedIn: [ishaan-goyal10](https://www.linkedin.com/in/ishaan-goyal10/)
- ğŸŒ Live Demo: [watchai-ten.vercel.app](https://watchai-ten.vercel.app/)
- ğŸ”§ Backend Repo: [IG05/testing](https://github.com/IG05/testing)

---

## ğŸ† Acknowledgments

- **OpenAI** for CLIP and Whisper models
- **Facebook AI** for FAISS similarity search
- **Hugging Face** for NLP model infrastructure
- **Google Cloud** and **AWS** for cloud services
- **Vercel** for seamless deployment experience

---

<div align="center">
  <strong>â­ Star this repo if you found it helpful!</strong>
</div>
